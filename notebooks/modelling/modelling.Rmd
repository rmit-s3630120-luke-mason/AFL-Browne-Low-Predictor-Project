---
title: "AFL Modelling"
output: html_notebook
---

Read train and test sets from files.
```{r}
train <- read.csv("../../data/train_set.csv")
test <- read.csv("../../data/test_set.csv")


```

# Modelling

```{r}
summary(train)
y <- train$Brownlow.Votes
x <- as.matrix(train[,7:30])
x <- -x[,-16]
xPred = as.matrix(test[,7:30])
xPred <- -xPred[,-16]

dataList = list(
  x = x,
  y = y,
  xPred = xPred,
  rowCount = length(y),
  colCount = ncol(x), 
  predCount = nrow(xPred)
)



```



### JAGS Model
```{r}
	modelString = "
	data {
	  yMean <- mean(y)
	 
	  # Specify the priors for original beta parameters
	  # Prior locations to reflect the expert information
	  # Regression coeffient in LR indicates how much 1 unit of change of the 
	  # predictor increases the log odds of outcome 1.
	  # Set to overall mean a priori based on the interpretation of constant term in regression
	  
	  mu0 <- yMean 
	  mu[1] <- 0
	  mu[2] <- 1/54*0.36
	  mu[3] <- 1/36*0.36
	  mu[4] <- 1/19*0.067
	  mu[5] <- 1/35*0.36
	  mu[6] <- 1/11*1.2
	  mu[7] <- 1/7*0.067
	  mu[8] <- 0
	  mu[9] <- 1/19*0.067
	  mu[10] <- 0
	  mu[11] <- 1/16*0.36
	  mu[12] <- 1/36*1.2
	  mu[13] <- 1/15*0.067
	  mu[14] <- 1/9*0.067
	  mu[15] <- 0
	  mu[16] <- 1/32*1.2
	  mu[17] <- 1/40*0.067
	  mu[18] <- 1/9*0.067
	  mu[19] <- 1/13*0.36
	  mu[20] <- 0
	  mu[21] <- 1/15*0.067
	  mu[22] <- 1/6*0.067
	  mu[23] <- 0
	  
	  # Prior variances to reflect the expert information
	  Var0   <- 1.00000 # Set simply to 1
	  for (i in 1:colCount) {
	    var[i] <- 0.25
	  }  
	}
	# Model
	model {
	  beta0   ~ dnorm(mu0,  1/Var0)
	  for (j in 1:colCount) {
	    beta[j] ~ dnorm(mu[j], 1/var[j])
	    }
	  }
	  
	  
	  # ... variance as it is ...
	  precision ~ dexp(1/0.25) 
	  
	  for (i in 1:rowCount) {
	  
	    # Normal Likelihood
	    #a = 0
	    #for (i in 1:23) {
	    #b = beta[i] ~ dnorm(m[i], 1/Var[i])
	    #a = a+b
	    #beta0   ~ dnorm(mu0,  1/Var0) + a 
	    y[i] ~ dnorm(beta0 + 
	          (beta[1] * x[i,1]) +
	          (beta[2] * x[i,2]) +
	          (beta[3] * x[i,3]) +
	          (beta[4] * x[i,4]) +
	          (beta[5] * x[i,5]) +
	          (beta[6] * x[i,6]) +
	          (beta[7] * x[i,7]) +
	          (beta[8] * x[i,8]) +
	          (beta[9] * x[i,9]) +
	          (beta[10] * x[i,10]) +
	          (beta[11] * x[i,11]) +
	          (beta[12] * x[i,12]) +
	          (beta[13] * x[i,13]) +
	          (beta[14] * x[i,14]) +
	          (beta[15] * x[i,15]) +
	          (beta[16] * x[i,16]) +
	          (beta[17] * x[i,17]) +
	          (beta[18] * x[i,18]) +
	          (beta[19] * x[i,19]) +
	          (beta[20] * x[i,20]) +
	          (beta[21] * x[i,21]) +
	          (beta[22] * x[i,22]) +
	          (beta[23] * x[i,23])
	          , precision)
	  }
	    # Compute predictions at every step of the MCMC
	    # HOW DO I MAKE THIS INTO A FOR LOOP AAAAAAA
  for (k in 1:predCount) {
    pred[k] <- beta0 + 
        (beta[1] * xPred[k,1]) + 
        (beta[2] * xPred[k,2]) + 
        (beta[3] * xPred[k,3]) + 
        (beta[4] * xPred[k,4]) +
        (beta[5] * xPred[k,5]) +
        (beta[6] * xPred[k,6]) + 
        (beta[7] * xPred[k,7]) + 
        (beta[8] * xPred[k,8]) + 
        (beta[9] * xPred[k,9]) +
        (beta[10] * xPred[k,10]) +
        (beta[11] * xPred[k,11]) + 
        (beta[12] * xPred[k,12]) + 
        (beta[13] * xPred[k,13]) + 
        (beta[14] * xPred[k,14]) +
        (beta[15] * xPred[k,15]) +
        (beta[16] * xPred[k,16]) +
        (beta[17] * xPred[k,17]) +
        (beta[18] * xPred[k,18]) +
        (beta[19] * xPred[k,19]) +
        (beta[20] * xPred[k,20]) +
        (beta[21] * xPred[k,21]) +
        (beta[22] * xPred[k,22]) +
        (beta[23] * xPred[k,23]) 
  }

}"
	
	writeLines(modelString, con="TEMPmodel.txt")
```
### Run JAGS
```{r}

parameters = c("beta0")
for ( i in 1:23){
  parameters = c(parameters, paste0("beta[",i,"]"))
}
for ( i in 1:nrow(xPred)){
  parameters = c(parameters, paste0("pred[",i,"]"))
}

adaptSteps = 50
burnInSteps = 100
nChains = 2
thinSteps = 17
numSavedSteps = 15000

nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains )

startTime = proc.time()
# sink("debug2.txt")
runJagsOut <- run.jags( method="parallel" ,
                        model="TEMPmodel.txt" ,
                        monitor=parameters  ,
                        data=dataList ,
                        n.chains=nChains ,
                        adapt=adaptSteps ,
                        burnin=burnInSteps ,
                        sample=numSavedSteps ,
                        thin=thinSteps , summarise=FALSE , plots=FALSE )
stopTime = proc.time()
duration = stopTime - startTime
show(duration)
codaSamples = as.mcmc.list( runJagsOut )
# sink()
# save( codaSamples , file=paste("A2Run4","Mcmc.Rdata",sep="") )
# save.image(file='A2Run4.RData')
```

### Results
